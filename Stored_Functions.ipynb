{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install nbimporter\n",
    "import nbimporter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, auc, roc_auc_score, precision_recall_curve, confusion_matrix, roc_curve, plot_roc_curve\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, cross_val_score\n",
    "import nbimporter\n",
    "#For upsampling data\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "from tqdm import tqdm\n",
    "#!pip install pickle-mixin\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_writing(df):\n",
    "    '''Remove whitescpace and special characters and make everything lower case for better handling of data.\n",
    "    Input and output: Dataframe '''\n",
    "    #make all strings lowercase to avoid label differences due to capitalization\n",
    "    for col in df.select_dtypes('object').columns:\n",
    "        df[col] = df[col].str.lower()  \n",
    "    #column names to list\n",
    "    cols = list(df.columns) \n",
    "    #for every list entry in cols: replace whitespace and special character by underscore and change names to lowercase  \n",
    "    cols = [name.replace(' ', '_').replace('-', '_').lower() for name in cols] \n",
    "    #replace dataframe columns by updated list entries\n",
    "    #return updated dataframe\n",
    "    df.columns = cols\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for all prior preprocessing steps to be applied to validation and test data\n",
    "def adapt_writing_test (df):\n",
    "    #Remove whitespace, special characters, make everything lowercase\n",
    "    adapt_writing(df)\n",
    "    \n",
    "    #If there are no duplicates, remove stammnummer and anruf id from df\n",
    "    if df.duplicated(subset = ['stammnummer', 'anruf_id']).sum() == 0:\n",
    "        df.drop(['stammnummer', 'anruf_id'], axis = 1, inplace = True)\n",
    "    else:\n",
    "        print(df[df.duplicated()])\n",
    "        \n",
    "    #Compute new feature\n",
    "    df['letzte_kampagne'] = df.ergebnis_letzte_kampagne\n",
    "    #If there was no prior contact, letzte Kampagne is set to 'kein kontakt'\n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i, 'anzahl_kontakte_letzte_kampagne'] == 0:\n",
    "            df.loc[i,'letzte_kampagne'] = 'kein kontakt' \n",
    "    #drop the original features\n",
    "    df.drop(['anzahl_kontakte_letzte_kampagne', 'ergebnis_letzte_kampagne'], axis = 1, inplace = True)\n",
    "    \n",
    "    #Fill in the NaNs of tage_seit_letzter_kampagne with 0 if there was no prior contact.\n",
    "    df.tage_seit_letzter_kampagne.fillna(0, inplace = True)\n",
    "    \n",
    "    #Reduce number of classes in art_der_anstellung\n",
    "    df['erwerbstaetigkeit'] = 'angestellt'\n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i, 'art_der_anstellung'] in ['hausfrau', 'arbeitslos', 'rentner']:\n",
    "            df.loc[i,'erwerbstaetigkeit'] = 'nicht erwerbstätig'\n",
    "        elif df.loc[i, 'art_der_anstellung'] == 'student':\n",
    "            df.loc[i,'erwerbstaetigkeit'] = 'student'\n",
    "        elif df.loc[i, 'art_der_anstellung'] in ['selbständig', 'gründer']:\n",
    "            df.loc[i,'erwerbstaetigkeit'] = 'selbständig'\n",
    "    #drop original feature\n",
    "    df.drop('art_der_anstellung', axis = 1, inplace = True)\n",
    "    \n",
    "    #missings/ unbekannt labels are replaced by the column's mode\n",
    "    cols = ['schulabschluß', 'kontaktart', 'letzte_kampagne']\n",
    "    for col in cols:\n",
    "        df[col].replace('unbekannt', np.nan, inplace = True)\n",
    "        df[col].fillna(df[col].mode()[0], inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocssing: Rescale numeric data, encode categorical data and make a list with feature names (needed for feature importancce)\n",
    "def preprocessing(X_train, X_val, y_train, y_val, train_only = False):\n",
    "    '''Function to rescale numeric data and encode categorical data of train dataframe and optionally, validation data.\n",
    "    Training data is additionally upsampled using SMOTENC\n",
    "    Input:\n",
    "    X_train: training features as pd.DataFrame\n",
    "    y_train: training target as pd.DataFrame\n",
    "    X_val: validation features as pd.DataFrame\n",
    "    y_val: validation target as pd.DataFrame\n",
    "    train_only: Bool, if False, training and validation are to be transformed, if True, only training data is transformed'''\n",
    "    \n",
    "    #List of categorical features\n",
    "    cat = list(X_train.select_dtypes('object'))\n",
    "    \n",
    "    #Indices of categorical data\n",
    "    cat_indices = []\n",
    "    for col in cat:\n",
    "        cat_indices.append(X_train.columns.get_loc(col))\n",
    "\n",
    "    #numerical features\n",
    "    num = list(X_train.select_dtypes('number')) \n",
    "    \n",
    "    #Pipeline for feature transformation: rescale numerical features, numerically encode categorical features\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('scale_numceric', RobustScaler(), num),\n",
    "        ('encode_cat', OneHotEncoder(drop = 'first'), cat)], \n",
    "        remainder = 'passthrough')\n",
    "    \n",
    "    #fit to train data\n",
    "    preprocessor.fit(X_train)\n",
    "    \n",
    "    #transform train data\n",
    "    X_train = pd.DataFrame(preprocessor.transform(X_train))\n",
    "    y_train = pd.get_dummies(y_train, drop_first = True)\n",
    "    \n",
    "    #get features names \n",
    "    feature_names = num + list(preprocessor.named_transformers_['encode_cat'].get_feature_names())\n",
    "    \n",
    "    #Oversampling train data via smotenc \n",
    "    X_sm, y_sm = SMOTENC(categorical_features = cat_indices, random_state = 42, sampling_strategy = 'minority', n_jobs = -1).fit_sample(X_train, y_train)\n",
    "    \n",
    "    if train_only == True:\n",
    "        return np.array(X_sm), np.array(y_sm), feature_names\n",
    "    else:\n",
    "        #transform validation data\n",
    "        X_val = pd.DataFrame(preprocessor.transform(X_val))\n",
    "        y_val = pd.get_dummies(y_val, drop_first = True)\n",
    "        return np.array(X_sm), np.array(X_val), np.array(y_sm), np.array(y_val), feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_train, y_proba_train, y_test, y_proba):\n",
    "    print(f'Baseline ROC AUC: {roc_auc_score(y_val, [1 for _ in range(len(y_val))])}')\n",
    "    print(f'Train ROC AUC Score: {roc_auc_score(y_train, y_proba_t)}')\n",
    "    print(f'Validation ROC AUC  Score: {roc_auc_score(y_val, y_proba)}')\n",
    "    \n",
    "    FPR, TPR, Thresholds = roc_curve(y_test, y_proba)\n",
    "    FPRt, TPRt, Thresholdst = roc_curve(y_train, y_proba_t)\n",
    "\n",
    "    plt.plot(FPR, TPR,'b-',label = 'validation')\n",
    "    plt.plot(FPRt, TPRt,'r-',label = 'train')\n",
    "    plt.plot([0,1],[0,1],'k--', label = 'random')\n",
    "    plt.plot([0,0,1,1],[0,1,1,1],'g--',label = 'perfect')\n",
    "    plt.legend()\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict test_y values and probabilities based on fitted logistic regression model\n",
    "\n",
    "#pred_y = logistic_regression.predict(X_test) \n",
    "\n",
    "#probs_y=logistic_regression.predict_proba(X_test) \n",
    "  # probs_y is a 2-D array of probability of being labeled as 0 (first column of array) vs 1 (2nd column in array)\n",
    "def define_thresholds(y_test, y_proba):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, y_proba)\n",
    "    #retrieve probability of being 1(in second column of probs_y)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    plt.title(\"Precision-Recall vs Threshold Chart\")\n",
    "    plt.plot(thresholds, precision[: -1], \"b--\", label = \"Precision\")\n",
    "    plt.plot(thresholds, recall[: -1], \"r--\", label = \"Recall\")\n",
    "    plt.ylabel(\"Precision, Recall\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance\n",
    "#Since it is biased towards continuous or high-cardinality features, I do not use sklearn's feature importance but use a drop-column-approach. This computationally \n",
    "# more expensive but gives better results.\n",
    "def dc_importance(model, X_train, y_train, X_val, y_val, feature_names):\n",
    "    '''Get feature importance using a drop-column-approach: Importance is calculated based on score changes after removing the feature.\n",
    "    Input: X, y as pd.DataFrames, feature_names as list'''\n",
    "    #Fit model with all features\n",
    "    model.fit(X_train, y_train)\n",
    "    y_proba = model.predict_proba(X_val)\n",
    "    benchmark_score = roc_auc_score(y_val, y_proba[:,1]) \n",
    "    \n",
    "    importances = []\n",
    "    for col in tqdm(pd.DataFrame(X_train).columns):\n",
    "        model.fit(pd.DataFrame(X_train).drop(col, axis = 1), y_train)\n",
    "        y_proba_d = model.predict_proba(pd.DataFrame(X_val).drop(col, axis = 1))\n",
    "        drop_score = roc_auc_score(y_val, y_proba_d[:,1]) \n",
    "        importances.append(benchmark_score - drop_score)\n",
    "    importances_df = pd.DataFrame(data = [feature_names, rf_model.feature_importances_]).transpose()\n",
    "    importances_df.rename({1: 'importance', 0: 'feature'}, axis = 1, inplace = True)\n",
    "    importances_df.sort_values('importance', ascending = False, inplace = True)\n",
    "    return importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision recall curve\n",
    "def prec_recall(y, y_proba):\n",
    "    precision, recall, thresholds = precision_recall_curve(y, y_proba)\n",
    "    plt.plot(recall, precision)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
